{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gaussian(x, mu, sigma2):\n",
    "\n",
    "    coeff = 1 / np.sqrt(2 * np.pi * sigma2)\n",
    "    exponent = np.exp(-((x - mu) ** 2) / (2 * sigma2))\n",
    "\n",
    "    return coeff * exponent\n",
    "\n",
    "class GaussNaiveBayes :\n",
    "    \"\"\" Gaussian Naive Bayes model for multiclass classification\n",
    "    \n",
    "    @attrs:\n",
    "        n_classes:    the number of classes\n",
    "        feature_dist:    a 3D (n_classes x n_features x 2) NumPy array of the attribute distributions: mean and sigma2 for each features for each class\n",
    "                        \n",
    "                        ex : [[[mu, sigma2],   of feature 1\n",
    "                               [mu, sigma2],   of feature 2\n",
    "                               [mu, sigma2]],  of feature 3 of class 1\n",
    "                               \n",
    "                               [[mu, sigma2],  of feature 1\n",
    "                               [mu, sigma2],   of feature 2\n",
    "                               [mu, sigma2]]]  of feature 3 of class 2\n",
    "\n",
    "        priors: a 1D NumPy array of the priors distribution\n",
    "\n",
    "                        ex : [p_class1, p_class2, p_class3]\n",
    "    \"\"\"\n",
    "    def __init__ (self):\n",
    "        self.n_classes = None # computed at training\n",
    "        self.feature_dist = None\n",
    "        self.priors = None\n",
    "\n",
    "        self.laplace_smoothing = 1 # Default value for the smoothing parameter\n",
    "\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        \"\"\" Trains the model, using maximum likelihood estimation.\n",
    "        @params:\n",
    "            X_train: a 2D (n_examples x n_features) numpy array\n",
    "            y_train: a 1D (n_examples) numpy array of the corresponding labels\n",
    "        @return:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.n_classes = len(set(y_train))\n",
    "        n_features = X_train.shape[1]\n",
    "\n",
    "        self.priors = np.zeros(self.n_classes)\n",
    "        self.feature_dist = np.zeros((self.n_classes, n_features, 2))\n",
    "\n",
    "        n_examples = X_train.shape[0]\n",
    "\n",
    "        for class_label in range(self.n_classes):\n",
    "            X_class = X_train [y_train == class_label]\n",
    "\n",
    "            # Computing prior with Laplace smoothing\n",
    "            total_class = X_class.shape[0]\n",
    "            a = self.laplace_smoothing\n",
    "            self.priors[class_label] = (total_class +a) /(n_examples +a * self.n_classes)\n",
    "\n",
    "            # Computing the moments (mean mu and variance sigma2)\n",
    "            mu = np.mean(X_class, axis=1)\n",
    "            sigma2 = np.var(X_class, axis = 1)\n",
    "            \n",
    "            # saving the mu and sigma for later predictions\n",
    "            self.feature_dist [class_label, :, :] = np.vstack(mu , sigma2).T\n",
    "\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        \"\"\" Outputs a predicted label for each input in inputs.\n",
    "\n",
    "        @params:\n",
    "            inputs: a 2D NumPy array containing inputs (n_requests * n_features)\n",
    "        @return:\n",
    "            a 1D numpy array of predictions\n",
    "        \"\"\"\n",
    "\n",
    "        predictions = np.zeros(len(inputs))\n",
    "        for index, input in enumerate(inputs) :\n",
    "\n",
    "            logprobs = np.log(self.priors)\n",
    "            for class_label in range(self.n_classes):\n",
    "                mu = self.feature_dist[class_label, :, 0] # All mus for all features at a time \n",
    "                sigma2 = self.feature_dist[class_label, :, 1]\n",
    "\n",
    "                logprobs[class_label] += np.sum(np.log(gaussian(input, mu, sigma2)))\n",
    "\n",
    "            predictions[index] = np.argmax(logprobs)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def accuracy(self, X_test, y_test):\n",
    "        \"\"\" Outputs the accuracy of the trained model on a given dataset (data).\n",
    "\n",
    "        @params:\n",
    "            X_test: a 2D numpy array of examples\n",
    "            y_test: a 1D numpy array of labels\n",
    "        @return:\n",
    "            a float number indicating accuracy (between 0 and 1)\n",
    "        \"\"\"\n",
    "\n",
    "        y_pred = self.predict(X_test)\n",
    "        return np.mean(y_pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 12] [11 13]\n",
      "[0.00655861 0.00490845]\n",
      "[-5.02697708 -5.31679783]\n",
      "-10.343774906014824\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_dist = np.array([[[1,2],[3,4]],\n",
    "                         [[5,6],[7,8]],\n",
    "                         [[10,11],[12,13]]])\n",
    "\n",
    "\n",
    "class_label = 2\n",
    "\n",
    "mu = feature_dist[class_label, :, 0]\n",
    "sigma2 = feature_dist[class_label, :, 1]\n",
    "\n",
    "input = [2,3]\n",
    "print(mu, sigma2)\n",
    "print(gaussian(input, mu, sigma2))\n",
    "print(np.log(gaussian(input, mu, sigma2)))\n",
    "print(np.sum(np.log(gaussian(input, mu, sigma2))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data2060",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
